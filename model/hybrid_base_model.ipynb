{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7bd624f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import re\n",
    "from collections import  Counter\n",
    "from sklearn.model_selection import train_test_split \n",
    "from torchmetrics import R2Score\n",
    "from torch.nn import MSELoss\n",
    "from torch.optim import Adam\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "328526dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151968 9448\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Movie ID', 'Title', 'Overview', 'Genres', 'Release Date', 'Runtime',\n",
       "       'Average Rating', 'Vote Count', 'Popularity', 'Budget', 'Adult',\n",
       "       'Poster Path', 'Backdrop Path', 'Cast', 'Director', 'Keywords',\n",
       "       'Production Companies', 'Production Countries', 'Similar Movies',\n",
       "       'Movie Homepage'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating=pd.read_csv(r'D:\\movrec\\data_preprocessing\\cpdata4v2\\ratings.csv')\n",
    "movies=pd.read_csv(r'D:\\movrec\\data_preprocessing\\cpdata3v2\\movies.csv')\n",
    "user_num=len(pd.unique(rating['userId']))+1\n",
    "movie_num=len(pd.unique(rating['movieId']))+1\n",
    "print(user_num,movie_num)\n",
    "train,test=train_test_split(rating,test_size=0.09,stratify=rating['userId'])\n",
    "train=train.to_numpy()\n",
    "test=test.to_numpy()\n",
    "movies.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d82fdbfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Runtime', 'Popularity', 'Budget', 'Adult', 'year', 'month', 'day'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "user_train=torch.tensor(train[:,0],dtype=torch.long)\n",
    "movie_train=torch.tensor(train[:,1],dtype=torch.int32)\n",
    "rating_train=torch.tensor(train[:,2],dtype=torch.float32)\n",
    "training_data=torch.utils.data.DataLoader(torch.utils.data.TensorDataset(user_train,movie_train,rating_train),batch_size=128)\n",
    "#delete unneed data\n",
    "user_train=None\n",
    "movie_train=None\n",
    "rating_train=None\n",
    "user_val=torch.tensor(test[:,0],dtype=torch.long)\n",
    "movie_val=torch.tensor(test[:,1],dtype=torch.int32)\n",
    "rating_val=torch.tensor(test[:,2],dtype=torch.float32)\n",
    "dev_data=torch.utils.data.DataLoader(torch.utils.data.TensorDataset(user_val,movie_val,rating_val),batch_size=1024)\n",
    "#delete unneed data\n",
    "user_val=None\n",
    "movie_val=None\n",
    "rating_val=None\n",
    "#sort by movie id to ensure bring data with correct index because  the range of data is from 1 to 7616 with no trap\n",
    "movies.sort_values(by='Movie ID',inplace=True)\n",
    "movies.drop(labels=['Movie ID','Poster Path','Backdrop Path','Keywords','Similar Movies','Movie Homepage'],axis=1,inplace=True)\n",
    "movies['Release Date']=pd.to_datetime(movies['Release Date'])\n",
    "numeric_movie_data=movies.select_dtypes(include=['number','bool','datetime'])\n",
    "movies.drop(labels=numeric_movie_data.columns,axis=1,inplace=True)\n",
    "numeric_movie_data['year']=numeric_movie_data['Release Date'].dt.year\n",
    "numeric_movie_data['month']=numeric_movie_data['Release Date'].dt.month\n",
    "numeric_movie_data['day']=numeric_movie_data['Release Date'].dt.day\n",
    "numeric_movie_data.drop(labels=['Release Date','Average Rating','Vote Count'],axis=1,inplace=True)\n",
    "print(numeric_movie_data.columns)\n",
    "numeric_movie_data=torch.tensor(numeric_movie_data.to_numpy().astype(np.float32),device=device,dtype=torch.float32)\n",
    "max_movie_id = int(torch.max(torch.tensor(train[:,1], dtype=torch.long))) - 1\n",
    "if max_movie_id >= numeric_movie_data.shape[0]:\n",
    "    raise ValueError(f\"Movie id out of bounds: {max_movie_id} vs. numeric_movie_data rows {numeric_movie_data.shape[0]}\")\n",
    "\n",
    "train=None\n",
    "test=None\n",
    "rating=None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2baa988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9447, 7])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_movie_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5601aa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(numeric_movie_data.shape[1]):\n",
    "    avg=torch.mean(numeric_movie_data[:,i])\n",
    "    std=torch.std(numeric_movie_data[:,i])\n",
    "    if std==torch.nan:\n",
    "        std=1\n",
    "    if i!=3:\n",
    "        numeric_movie_data[:,i]=(numeric_movie_data[:,i]-avg)/std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3447a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.5418, -0.5043, -0.5865,  0.0000, -0.5148,  0.8822,  0.6429],\n",
       "        [-1.4963, -0.5135, -0.5865,  0.0000, -0.6210,  0.8822,  0.1742],\n",
       "        [-0.4032, -0.3931, -0.4832,  0.0000, -0.1429,  1.4700, -0.7632],\n",
       "        [ 0.0978, -0.4840, -0.0445,  0.0000, -0.2492,  0.8822, -0.0602],\n",
       "        [ 0.6443,  0.6326, -0.3026,  0.0000, -1.0992, -0.5873,  1.1116]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_movie_data[:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8145cb19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.9787234042553195\n",
      "2.6343812850640416\n",
      "46.69344765534032\n",
      "1.0370487985603896\n",
      "3.2065205885466286\n",
      "1.4553826611622738\n"
     ]
    }
   ],
   "source": [
    "class Tokenizer:\n",
    "    def __init__(self,split,max_seq_len):\n",
    "        self.tokn=list()\n",
    "        self.vocab=list()\n",
    "        self.index=dict()\n",
    "        self.num=list()\n",
    "        self.max_len=max_seq_len\n",
    "        self.split=split\n",
    "    def standerization(self,data:str,split:str):\n",
    "        data=str(data)\n",
    "        data=data.lower()\n",
    "        data=re.sub('[\\.@#%^&*()!:;\\\\\\$\\'\"]*',\"\",data)\n",
    "        if split != None:\n",
    "            data=re.split(split,data)\n",
    "            data=list(map(lambda x:re.sub(' ',\"\",x),data))\n",
    "        else:\n",
    "            data=re.sub(r' ',\"\",data)\n",
    "        return data\n",
    "    def add_to_vocab(self,row):\n",
    "        if isinstance(row, list):\n",
    "            for word in row:\n",
    "                if word not in self.vocab:\n",
    "                    self.vocab.append(word)\n",
    "        elif isinstance(row,str):\n",
    "            if row not in self.vocab:\n",
    "                self.vocab.append(row)\n",
    "    def build_vocab(self):\n",
    "        for li in self.tokn: \n",
    "            self.add_to_vocab(li)\n",
    "    def maper(self):\n",
    "\n",
    "        self.index={word : idx+2 for idx,word in enumerate(self.vocab)}\n",
    "        for idx,li in enumerate(self.tokn):\n",
    "            if isinstance(li, list):\n",
    "                self.num.append(list())\n",
    "                for word in li:\n",
    "                    self.num[idx].append(self.index[word])\n",
    "            else:\n",
    "                self.num.append(self.index[li])\n",
    "    def padding(self):\n",
    "\n",
    "        for i in self.num:\n",
    "            if not isinstance(i, list):\n",
    "                break\n",
    "            while len(i)>self.max_len:\n",
    "                i.pop(-1)\n",
    "            while len(i)<self.max_len:\n",
    "                i.append(1)\n",
    "    def transform(self,data):\n",
    "        self.tokn=list(map(lambda word:self.standerization(word,self.split),data))\n",
    "        c=0\n",
    "        su=0\n",
    "        if self.split!=None:\n",
    "            for i in self.tokn:\n",
    "                su+=len(i)\n",
    "                c+=1\n",
    "            print(su/c)\n",
    "        self.build_vocab()\n",
    "        self.maper()\n",
    "        self.padding()\n",
    "        return  self.num\n",
    "title=torch.tensor(Tokenizer(max_seq_len=1,split=None).transform(movies['Title']),device=device,dtype=torch.long)\n",
    "cast=torch.tensor(Tokenizer(max_seq_len=3,split=',').transform(movies['Cast'].to_list()),device=device,dtype=torch.long)\n",
    "genre=torch.tensor(Tokenizer(max_seq_len=4,split=',').transform(movies['Genres'].to_list()),device=device,dtype=torch.long)\n",
    "overrview=torch.tensor(Tokenizer(max_seq_len=50,split=' ').transform(movies['Overview'].to_list()),device=device,dtype=torch.long)\n",
    "director=torch.tensor(Tokenizer(max_seq_len=1,split=',').transform(movies['Director'].to_list()),device=device,dtype=torch.long).squeeze()\n",
    "production_compaines=torch.tensor(Tokenizer(max_seq_len=3,split=',').transform(movies['Production Companies'].to_list()),device=device,dtype=torch.long)\n",
    "production_countries=torch.tensor(Tokenizer(max_seq_len=2,split=',').transform(movies['Production Countries'].to_list()),device=device,dtype=torch.long)\n",
    "movies=None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68c87600",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FunctionalModel(torch.nn.Module):\n",
    "    def __init__(self, user_size):\n",
    "        super(FunctionalModel, self).__init__()\n",
    "        self.user_emb = torch.nn.Embedding(user_size, 100)\n",
    "        self.title_emb=torch.nn.Embedding(torch.max(title)+1,20)\n",
    "        self.overreview_emb=torch.nn.Embedding(torch.max(overrview)+1,20)\n",
    "        self.director_emb=torch.nn.Embedding(torch.max(director)+1,8)\n",
    "        self.cast_emb=torch.nn.Embedding(torch.max(cast)+1,10)\n",
    "        self.genre_emb=torch.nn.Embedding(torch.max(genre)+1,15)\n",
    "        self.prod_comp_emb=torch.nn.Embedding(torch.max(production_compaines)+1,10)\n",
    "        self.prod_count_emb=torch.nn.Embedding(torch.max(production_countries)+1,10)\n",
    "        self.dropout=torch.nn.Dropout(0.2)\n",
    "    def forward(self, user_ids, movie_ids):\n",
    "        #because index of tokenized data start from 0 not one \n",
    "        movie_ids=movie_ids-1 \n",
    "        user =self.user_emb(user_ids)\n",
    "        tit=self.title_emb(title[movie_ids])\n",
    "        ovrv=self.overreview_emb(overrview[movie_ids])\n",
    "        dire=self.director_emb(director[movie_ids])\n",
    "        ct=self.cast_emb(cast[movie_ids])\n",
    "        gn=self.genre_emb(genre[movie_ids])\n",
    "        pd_cmp=self.prod_comp_emb(production_compaines[movie_ids])\n",
    "        pd_count=self.prod_count_emb(production_countries[movie_ids])\n",
    "        num_data=numeric_movie_data[movie_ids]\n",
    "        #because the diff of sequence  we must reduce the dim without lossing of data\n",
    "        ovrv_vec=ovrv.mean(dim=1)\n",
    "        ct_vec=ct.mean(dim=1)\n",
    "        gn_vec=gn.mean(dim=1)\n",
    "        pd_cmp_vec=pd_cmp.mean(dim=1)\n",
    "        pd_count_vec=pd_count.mean(dim=1) \n",
    "        movie=torch.cat((tit,ovrv_vec,dire,ct_vec,gn_vec,pd_cmp_vec,pd_count_vec,num_data),dim=-1)\n",
    "        movie=self.dropout(movie)\n",
    "        user=self.dropout(user)\n",
    "        x = torch.sum(user * movie, dim=-1, keepdim=True)\n",
    "        return x.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e4a7cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_base_model=FunctionalModel(user_num)\n",
    "path=r'D:\\movrec\\model\\hybrid model\\hybird_base_model\\base_model_MAE_0.7609.pth'\n",
    "hybrid_base_model.load_state_dict(torch.load(path))\n",
    "hybrid_base_model=hybrid_base_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36913888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\\5, loss is 0.704, R2 result is 0.2304,loss of dev0.5782549159024435, with R2 0.45673292875289917\n",
      "2\\5, loss is 0.6775, R2 result is 0.2828,loss of dev0.5718418915470983, with R2 0.4655442237854004\n",
      "3\\5, loss is 0.6686, R2 result is 0.3001,loss of dev0.5699130545195182, with R2 0.46868211030960083\n",
      "4\\5, loss is 0.6636, R2 result is 0.3101,loss of dev0.5699675238803773, with R2 0.4697972536087036\n",
      "5\\5, loss is 0.6602, R2 result is 0.3165,loss of dev0.5683957577617899, with R2 0.4702790379524231\n"
     ]
    }
   ],
   "source": [
    "adam=Adam(hybrid_base_model.parameters(),lr=1e-4)\n",
    "metric=R2Score().to(device)\n",
    "critery=torch.nn.L1Loss()\n",
    "torch.backends.cudnn.benchmark = True\n",
    "epoch=5\n",
    "for ep in range(epoch):\n",
    "    hybrid_base_model.train()\n",
    "    metric.reset()\n",
    "    runing_loss=0.0\n",
    "    for idx,data in enumerate(training_data):\n",
    "        u,m,r=data\n",
    "        adam.zero_grad()\n",
    "        u=u.to(device)\n",
    "        m=m.to(device)\n",
    "        r=r.to(device)\n",
    "        output=hybrid_base_model(u,m)        \n",
    "        loss=critery(output,r)\n",
    "        loss.backward()\n",
    "        adam.step()\n",
    "        runing_loss+=loss.item()\n",
    "        metric.update(output.squeeze(),r.squeeze())\n",
    "        str_out=f'{idx}\\{len(training_data)}, loss is {runing_loss/(idx+1):.4}\\r'\n",
    "        print(str_out,end=\"\")\n",
    "    result=metric.compute()\n",
    "    print(len(str_out)*\"\",end='')\n",
    "    print(f'{ep+1}\\{epoch}, loss is {runing_loss/len(training_data):.4}, R2 result is {result:.4}', end=\"\")\n",
    "    hybrid_base_model.eval()\n",
    "    metric.reset()\n",
    "    runing_loss=0.0\n",
    "    with torch.no_grad():\n",
    "        for u,m,r in dev_data:\n",
    "            u=u.to(device)\n",
    "            m=m.to(device)\n",
    "            r=r.to(device)\n",
    "            output=hybrid_base_model(u,m)\n",
    "            loss=critery(output.squeeze(),r.squeeze())\n",
    "            runing_loss+=loss.item()\n",
    "            metric.update(output,r)\n",
    "        result=metric.compute()\n",
    "        print(f',loss of dev{runing_loss/len(dev_data)}, with R2 {result}')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fda9379",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=r'D:\\movrec\\model\\hybrid model\\hybird_base_model'\n",
    "import os\n",
    "os.makedirs(path,exist_ok=True)\n",
    "torch.save(hybrid_base_model.state_dict(),path+'\\\\base_model_MAE_0.6602.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c676fb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=r'D:\\movrec\\model\\toknized_tensor'\n",
    "torch.save(title,path+\"\\\\title.pt\")\n",
    "torch.save(overrview,path+\"\\\\overrview.pt\")\n",
    "torch.save(director,path+\"\\\\director.pt\")\n",
    "torch.save(cast,path+\"\\\\cast.pt\")\n",
    "torch.save(production_compaines,path+'\\\\production_compaines.pt')\n",
    "torch.save(production_countries,path+'\\\\production_countries.pt')\n",
    "torch.save(genre,path+'\\\\genre.pt')\n",
    "torch.save(numeric_movie_data,path+'\\\\numeric_movie_data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348becee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
