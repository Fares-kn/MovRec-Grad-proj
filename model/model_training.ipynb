{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68cda25c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import re\n",
    "from collections import  Counter\n",
    "from sklearn.model_selection import train_test_split \n",
    "from torchmetrics import R2Score\n",
    "from torch.nn import MSELoss\n",
    "from torch.optim import Adam\n",
    "from typing import Dict\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f509dee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151968 9448\n"
     ]
    }
   ],
   "source": [
    "rating=pd.read_csv(r'D:\\movrec\\data_preprocessing\\cpdata4v2\\ratings.csv')\n",
    "#movies=pd.read_csv(r'D:\\movrec\\data_preprocessing\\cpdata3v2\\movies.csv')\n",
    "user_num=len(pd.unique(rating['userId']))+1\n",
    "movie_num=len(pd.unique(rating['movieId']))+1\n",
    "print(user_num,movie_num)\n",
    "train,test=train_test_split(rating,test_size=0.09,stratify=rating['userId'])\n",
    "train=train.to_numpy()\n",
    "test=test.to_numpy()\n",
    "user_train=torch.tensor(train[:,0],dtype=torch.long)\n",
    "movie_train=torch.tensor(train[:,1],dtype=torch.int32)\n",
    "rating_train=torch.tensor(train[:,2],dtype=torch.float32)\n",
    "training_data=torch.utils.data.DataLoader(torch.utils.data.TensorDataset(user_train,movie_train,rating_train),batch_size=256)\n",
    "#delete unneed data\n",
    "user_train=None\n",
    "movie_train=None\n",
    "rating_train=None\n",
    "user_val=torch.tensor(test[:,0],dtype=torch.long)\n",
    "movie_val=torch.tensor(test[:,1],dtype=torch.int32)\n",
    "rating_val=torch.tensor(test[:,2],dtype=torch.float32)\n",
    "dev_data=torch.utils.data.DataLoader(torch.utils.data.TensorDataset(user_val,movie_val,rating_val),batch_size=1024)\n",
    "#delete unneed data\n",
    "user_val=None\n",
    "movie_val=None\n",
    "rating_val=None\n",
    "#  i do not need movies data all data is stored\n",
    "title=torch.load(r'D:\\movrec\\model\\toknized_tensor\\title.pt')\n",
    "cast=torch.load(r'D:\\movrec\\model\\toknized_tensor\\cast.pt')\n",
    "director=torch.load(r'D:\\movrec\\model\\toknized_tensor\\director.pt')\n",
    "genre=torch.load(r'D:\\movrec\\model\\toknized_tensor\\genre.pt')\n",
    "overrview=torch.load(r'D:\\movrec\\model\\toknized_tensor\\overrview.pt')\n",
    "numeric_movie_data=torch.load(r'D:\\movrec\\model\\toknized_tensor\\numeric_movie_data.pt')\n",
    "production_countries=torch.load(r'D:\\movrec\\model\\toknized_tensor\\production_countries.pt')\n",
    "production_compaines=torch.load(r'D:\\movrec\\model\\toknized_tensor\\production_compaines.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d34d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FunctionalModel(torch.nn.Module):\n",
    "    def __init__(self, user_size):\n",
    "        super(FunctionalModel, self).__init__()\n",
    "        self.user_emb = torch.nn.Embedding(user_size, 100)\n",
    "        self.title_emb=torch.nn.Embedding(torch.max(title)+1,20)\n",
    "        self.overreview_emb=torch.nn.Embedding(torch.max(overrview)+1,20)\n",
    "        self.director_emb=torch.nn.Embedding(torch.max(director)+1,8)\n",
    "        self.cast_emb=torch.nn.Embedding(torch.max(cast)+1,10)\n",
    "        self.genre_emb=torch.nn.Embedding(torch.max(genre)+1,15)\n",
    "        self.prod_comp_emb=torch.nn.Embedding(torch.max(production_compaines)+1,10)\n",
    "        self.prod_count_emb=torch.nn.Embedding(torch.max(production_countries)+1,10)\n",
    "        self.dropout=torch.nn.Dropout(0.2)\n",
    "    def forward(self, user_ids, movie_ids):\n",
    "        #because index of tokenized data start from 0 not one \n",
    "        movie_ids=movie_ids-1 \n",
    "        user =self.user_emb(user_ids)\n",
    "        tit=self.title_emb(title[movie_ids])\n",
    "        ovrv=self.overreview_emb(overrview[movie_ids])\n",
    "        dire=self.director_emb(director[movie_ids])\n",
    "        ct=self.cast_emb(cast[movie_ids])\n",
    "        gn=self.genre_emb(genre[movie_ids])\n",
    "        pd_cmp=self.prod_comp_emb(production_compaines[movie_ids])\n",
    "        pd_count=self.prod_count_emb(production_countries[movie_ids])\n",
    "        num_data=numeric_movie_data[movie_ids]\n",
    "        #because the diff of sequence  we must reduce the dim without lossing of data\n",
    "        ovrv_vec=ovrv.mean(dim=1)\n",
    "        ct_vec=ct.mean(dim=1)\n",
    "        gn_vec=gn.mean(dim=1)\n",
    "        pd_cmp_vec=pd_cmp.mean(dim=1)\n",
    "        pd_count_vec=pd_count.mean(dim=1) \n",
    "        movie=torch.cat((tit,ovrv_vec,dire,ct_vec,gn_vec,pd_cmp_vec,pd_count_vec,num_data),dim=-1)\n",
    "        movie=self.dropout(movie)\n",
    "        user=self.dropout(user)\n",
    "        x = torch.sum(user * movie, dim=-1, keepdim=True)\n",
    "        return x.squeeze()\n",
    "class ResNetBlock(torch.nn.Module):\n",
    "    def __init__(self,in_f,out_f,activation=torch.nn.ELU()):\n",
    "        super(ResNetBlock,self).__init__()\n",
    "        self.f1=torch.nn.Linear(in_f,out_f)\n",
    "        self.f2=torch.nn.Linear(out_f,out_f)\n",
    "        self.res=torch.nn.Linear(in_f,out_f)\n",
    "        self.batchNorm1=torch.nn.BatchNorm1d(out_f, momentum=0.3)\n",
    "        self.batchNorm2=torch.nn.BatchNorm1d(out_f,momentum=0.3)\n",
    "        self.activation=activation\n",
    "        \n",
    "    def forward(self,x):\n",
    "        shortcut=self.res(x)\n",
    "        x=self.f1(x)\n",
    "        x=self.batchNorm1(x)\n",
    "        x=self.activation(x)\n",
    "        x=self.f2(x)\n",
    "        x=self.batchNorm2(x)\n",
    "        x=x+shortcut\n",
    "        x=self.activation(x)\n",
    "        return x\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self,user_size,in_out_list:list,activation):\n",
    "        super(Model,self).__init__()\n",
    "        self.user_emb = torch.nn.Embedding(user_size, 100)\n",
    "        self.title_emb=torch.nn.Embedding(torch.max(title)+1,20)\n",
    "        self.overreview_emb=torch.nn.Embedding(torch.max(overrview)+1,20)\n",
    "        self.director_emb=torch.nn.Embedding(torch.max(director)+1,8)\n",
    "        self.cast_emb=torch.nn.Embedding(torch.max(cast)+1,10)\n",
    "        self.genre_emb=torch.nn.Embedding(torch.max(genre)+1,15)\n",
    "        self.prod_comp_emb=torch.nn.Embedding(torch.max(production_compaines)+1,10)\n",
    "        self.prod_count_emb=torch.nn.Embedding(torch.max(production_countries)+1,10)\n",
    "        self.layers=torch.nn.ModuleList() \n",
    "        in_f=100\n",
    "        for out_f in in_out_list:\n",
    "            self.layers.append(ResNetBlock(in_f,out_f,activation))\n",
    "            in_f=out_f\n",
    "        self.output=torch.nn.Linear(in_out_list[-1],1)\n",
    "\n",
    "        self.model=torch.nn.Sequential(*self.layers)\n",
    "    def forward(self,user_ids,movie_ids):\n",
    "        movie_ids=movie_ids-1 \n",
    "        user = self.user_emb(user_ids)\n",
    "        tit=self.title_emb(title[movie_ids])\n",
    "        ovrv=self.overreview_emb(overrview[movie_ids])\n",
    "        dire=self.director_emb(director[movie_ids])\n",
    "        ct=self.cast_emb(cast[movie_ids])\n",
    "        gn=self.genre_emb(genre[movie_ids])\n",
    "        pd_cmp=self.prod_comp_emb(production_compaines[movie_ids])\n",
    "        pd_count=self.prod_count_emb(production_countries[movie_ids])\n",
    "        ovrv_vec=ovrv.mean(dim=1)\n",
    "        ct_vec=ct.mean(dim=1)\n",
    "        gn_vec=gn.mean(dim=1)\n",
    "        pd_cmp_vec=pd_cmp.mean(dim=1)\n",
    "        pd_count_vec=pd_count.mean(dim=1) \n",
    "        num_data=numeric_movie_data[movie_ids]\n",
    "        movie=torch.cat((tit,ovrv_vec,dire,ct_vec,gn_vec,pd_cmp_vec,pd_count_vec,num_data),dim=-1)\n",
    "        result=user*movie\n",
    "        x=self.model(result)\n",
    "        x=self.output(x)\n",
    "        return x.squeeze()\n",
    "model=Model(user_num,[128,256,512],torch.nn.ReLU())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a3a9e777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_of_base=r'D:\\movrec\\model\\hybrid model\\hybird_base_model\\base_model_MAE_0.6602.pth'\n",
    "base_model=FunctionalModel(user_num)\n",
    "base_model.load_state_dict(torch.load(path_of_base))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "20c623bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "stat_dict = base_model.state_dict()\n",
    "with torch.no_grad():\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if name in stat_dict:\n",
    "            parameter.copy_(stat_dict[name])\n",
    "            parameter.requires_grad = False\n",
    "            print(parameter.requires_grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "65c1c19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 89043/89043 - Loss: 0.5300\n",
      "Epoch 1/5 - Train Loss: 0.5300, Train R2: 0.4845\n",
      "        Validation: Loss: 0.5235, R2: 0.4879\n",
      "Batch 89043/89043 - Loss: 0.5239\n",
      "Epoch 2/5 - Train Loss: 0.5239, Train R2: 0.4830\n",
      "        Validation: Loss: 0.5222, R2: 0.4870\n",
      "Batch 89043/89043 - Loss: 0.5223\n",
      "Epoch 3/5 - Train Loss: 0.5223, Train R2: 0.4816\n",
      "        Validation: Loss: 0.5208, R2: 0.4839\n",
      "Batch 89043/89043 - Loss: 0.5214\n",
      "Epoch 4/5 - Train Loss: 0.5214, Train R2: 0.4807\n",
      "        Validation: Loss: 0.5206, R2: 0.4834\n",
      "Batch 20939/89043 - Loss: 0.5211\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m ratings \u001b[38;5;241m=\u001b[39m ratings\u001b[38;5;241m.\u001b[39mto(device, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     16\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 17\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmovie_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, ratings)\n\u001b[0;32m     19\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\yosaf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\yosaf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[45], line 84\u001b[0m, in \u001b[0;36mModel.forward\u001b[1;34m(self, user_ids, movie_ids)\u001b[0m\n\u001b[0;32m     82\u001b[0m gn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenre_emb(genre[movie_ids])\n\u001b[0;32m     83\u001b[0m pd_cmp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprod_comp_emb(production_compaines[movie_ids])\n\u001b[1;32m---> 84\u001b[0m pd_count\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprod_count_emb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproduction_countries\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmovie_ids\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m ovrv_vec\u001b[38;5;241m=\u001b[39movrv\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     86\u001b[0m ct_vec\u001b[38;5;241m=\u001b[39mct\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\yosaf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1735\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1732\u001b[0m             tracing_state\u001b[38;5;241m.\u001b[39mpop_scope()\n\u001b[0;32m   1733\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m-> 1735\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_wrapped_call_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1736\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1737\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "optimizer = Adam(model.parameters(), lr=1e-3)\n",
    "criterion = torch.nn.L1Loss()\n",
    "model = model.to(device)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "num_epochs = 5\n",
    "r2_metric = R2Score().to(device)\n",
    "for epoch_idx in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss, batch_count = 0.0, 0\n",
    "    r2_metric.reset()\n",
    "    \n",
    "    for user_ids, movie_ids, ratings in training_data:\n",
    "        user_ids = user_ids.to(device, non_blocking=True)\n",
    "        movie_ids = movie_ids.to(device, non_blocking=True)\n",
    "        ratings = ratings.to(device, non_blocking=True)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(user_ids, movie_ids)\n",
    "        loss = criterion(output, ratings)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        r2_metric.update(output.float(), ratings.float())\n",
    "        batch_count += 1\n",
    "        print(\n",
    "            f\"\\rBatch {batch_count}/{len(training_data)} - Loss: {running_loss / batch_count:.4f}\\r\",end='',flush=True)\n",
    "    print()\n",
    "    train_loss = running_loss / batch_count\n",
    "    train_r2 = r2_metric.compute()\n",
    "    print(\n",
    "        f\"Epoch {epoch_idx+1}/{num_epochs} - \"\n",
    "        f\"Train Loss: {train_loss:.4f}, Train R2: {train_r2:.4f}\"\n",
    "    )\n",
    "    model.eval()\n",
    "    r2_metric.reset()\n",
    "    val_loss_total = 0.0\n",
    "    with torch.inference_mode():\n",
    "        for user_ids, movie_ids, ratings in dev_data:\n",
    "            user_ids = user_ids.to(device, non_blocking=True)\n",
    "            movie_ids = movie_ids.to(device, non_blocking=True)\n",
    "            ratings = ratings.to(device, non_blocking=True)\n",
    "\n",
    "            output = model(user_ids, movie_ids)\n",
    "            val_loss_total += criterion(output, ratings).item()\n",
    "            r2_metric.update(output.float(), ratings.float())\n",
    "\n",
    "    avg_val_loss = val_loss_total / len(dev_data)\n",
    "    val_r2 = r2_metric.compute()\n",
    "    print(\n",
    "        f\"        Validation: Loss: {avg_val_loss:.4f}, R2: {val_r2:.4f}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5252d4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),r'D:\\movrec\\model\\hybrid model\\adv_model\\model_4_5211.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b543158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3/89043 - Loss: 0.5284\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 89043/89043 - Loss: 0.5215\n",
      "Epoch 1/5 - Train Loss: 0.5215, Train R2: 0.4841\n",
      "        Validation: Loss: 0.5212, R2: 0.4854\n",
      "Batch 89043/89043 - Loss: 0.5211\n",
      "Epoch 2/5 - Train Loss: 0.5211, Train R2: 0.4839\n",
      "        Validation: Loss: 0.5210, R2: 0.4850\n",
      "Batch 89043/89043 - Loss: 0.5210\n",
      "Epoch 3/5 - Train Loss: 0.5210, Train R2: 0.4836\n",
      "        Validation: Loss: 0.5209, R2: 0.4848\n",
      "Batch 89043/89043 - Loss: 0.5209\n",
      "Epoch 4/5 - Train Loss: 0.5209, Train R2: 0.4834\n",
      "        Validation: Loss: 0.5208, R2: 0.4845\n",
      "Batch 89043/89043 - Loss: 0.5208\n",
      "Epoch 5/5 - Train Loss: 0.5208, Train R2: 0.4832\n",
      "        Validation: Loss: 0.5208, R2: 0.4843\n"
     ]
    }
   ],
   "source": [
    "\n",
    "optimizer = Adam(model.parameters(), lr=3e-4)\n",
    "criterion = torch.nn.L1Loss()\n",
    "model = model.to(device)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "num_epochs = 5\n",
    "r2_metric = R2Score().to(device)\n",
    "for epoch_idx in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss, batch_count = 0.0, 0\n",
    "    r2_metric.reset()\n",
    "    \n",
    "    for user_ids, movie_ids, ratings in training_data:\n",
    "        user_ids = user_ids.to(device, non_blocking=True)\n",
    "        movie_ids = movie_ids.to(device, non_blocking=True)\n",
    "        ratings = ratings.to(device, non_blocking=True)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(user_ids, movie_ids)\n",
    "        loss = criterion(output, ratings)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        r2_metric.update(output.float(), ratings.float())\n",
    "        batch_count += 1\n",
    "        print(\n",
    "            f\"\\rBatch {batch_count}/{len(training_data)} - Loss: {running_loss / batch_count:.4f}\\r\",end='',flush=True)\n",
    "    print()\n",
    "    train_loss = running_loss / batch_count\n",
    "    train_r2 = r2_metric.compute()\n",
    "    print(\n",
    "        f\"Epoch {epoch_idx+1}/{num_epochs} - \"\n",
    "        f\"Train Loss: {train_loss:.4f}, Train R2: {train_r2:.4f}\"\n",
    "    )\n",
    "    model.eval()\n",
    "    r2_metric.reset()\n",
    "    val_loss_total = 0.0\n",
    "    with torch.inference_mode():\n",
    "        for user_ids, movie_ids, ratings in dev_data:\n",
    "            user_ids = user_ids.to(device, non_blocking=True)\n",
    "            movie_ids = movie_ids.to(device, non_blocking=True)\n",
    "            ratings = ratings.to(device, non_blocking=True)\n",
    "\n",
    "            output = model(user_ids, movie_ids)\n",
    "            val_loss_total += criterion(output, ratings).item()\n",
    "            r2_metric.update(output.float(), ratings.float())\n",
    "\n",
    "    avg_val_loss = val_loss_total / len(dev_data)\n",
    "    val_r2 = r2_metric.compute()\n",
    "    print(\n",
    "        f\"        Validation: Loss: {avg_val_loss:.4f}, R2: {val_r2:.4f}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1d1c0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
